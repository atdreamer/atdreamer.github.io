一、5秒盾是什么

1、5秒盾指 Cloudflare 的“5 秒盾”（也叫 Cloudflare 5s Challenge）。这是 Cloudflare 用来防止[机器人](https://so.csdn.net/so/search?q=%E6%9C%BA%E5%99%A8%E4%BA%BA&spm=1001.2101.3001.7020)访问网站的一种机制，通常会显示一个“请稍等 5 秒钟”的页面或者“Just a moment”等形式，然后自动重定向到目标页面。
![Image](https://github.com/user-attachments/assets/e0614c46-2b62-4694-a1ab-cef1d8c0966e)

2、Cloudflare 是一种基于云技术的Web应用程序防火墙（WAF），旨在保护网站免受各种Web攻击，它能够在5秒内检测到并阻止恶意流量。

3、官方说明：https://www.cloudflare-cn.com/what-is-cloudflare/

二、如何判断该网站有Cloudflare反爬

1、常见的特征1：我们通过requests请求后，响应状态码是403，请求的时候会出现 Just a moment
```python
import requests
headers = {
    "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
}
url = "https://toppsta.com/books/series/29278/national-geographic-kids-readers-level-1"
res = requests.get(url, headers=headers, timeout=10)
print("============requests, res.status_code, res.cookies, res.text)
```
![Image](https://github.com/user-attachments/assets/82cc4742-5c87-480d-be74-e1fdbc6be538)

2、常见特征2：响应头里面的Server是cloudflare
![Image](https://github.com/user-attachments/assets/97dd8f91-acb8-4a73-99e7-131aca630fe8)

3、常见特征3：请求头Cookie常常有__cf_bm之类的开头，__cfduid,  __cf_clearance  等

三、Cloudflare绕过

1、【免费版5秒盾】在无痕模式下打开并没有跳出校验真人，而是直接是数据展示页面，但是req

uests请求会是403，免费版的5秒盾可以通过cloudscraper 库过；

模块安装：pip install cloudscraper
```python
import cloudscraper
scraper = cloudscraper.create_scraper()
url = 'https://toppsta.com/books/series/29278/national-geographic-kids-readers-level-1'
res = scraper.get(url)
print("============scraper的方式", res.status_code, res.cookies, res.text)
```
2、【免费版5秒盾】在无痕模式下打开并没有跳出确认真人界面，但是requests请求会是403，cloudscraper的请求也是403，但是通过curl_cffi库可以通过，检查了tls指纹；pip install curl_cffi  https://github.com/lwthiker/curl-impersonate  

参考文章：https://zhuanlan.zhihu.com/p/601474166

```python
from curl_cffi import requests as cffi_requests
res = cffi_requests.get("https://www.chinatimes.com/?chdtv", impersonate='chrome110', timeout=10)
print("============cffi_requests的方式", res.status_code, res.cookies, res.text)
```
3、DrissionPage自动化绕过
```python
# 过五秒盾反爬
from DrissionPage import ChromiumPage, ChromiumOptions
import platform
from loguru import logger
 
if platform.system().lower() == 'windows':
    co = ChromiumOptions().set_paths(browser_path=r"C:\Program Files (x86)\Microsoft\Edge\Application\msedge.exe")
    value = '确认您是真人'
else:
    co = ChromiumOptions().set_paths(browser_path=r"/opt/google/chrome/google-chrome")
    value = 'Verify you are human'
    co.headless(True)   # 设置无头加载  无头模式是一种在浏览器没有界面的情况下运行的模式，它可以提高浏览器的性能和加载速度
    co.incognito(True)  # 无痕隐身模式打开的话，不会记住你的网站账号密码的
    co.set_argument('--no-sandbox')  # 禁用沙箱 禁用沙箱可以避免浏览器在加载页面时进行安全检查,从而提高加载速度 默认情况下，所有Chrome 用户都启用了隐私沙盒选项  https://zhuanlan.zhihu.com/p/475639754
    co.set_argument("--disable-gpu")  # 禁用GPU加速可以避免浏览器在加载页面时使用过多的计算资源，从而提高加载速度
    co.set_user_agent(user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36')  # 设置ua
 
 
browser = ChromiumPage(co)  # 创建对象
browser.set.window.max()
browser.get("https://cn.airbusan.com/content/common/customercenter/noticeList", retry=3, interval=2, timeout=15)   # 访问网
 
logger.info(f"user_agent is {browser.user_agent}")
browser.wait(2)
for i in range(20):
    if browser.ele(f'x://input[@value="{value}"]', timeout=3):
        logger.warning(f"retry {i+1} times, Verify you are human click now")
        browser.ele(f'x://input[@value="{value}"]').click()
        browser.wait(2)
    if not browser.cookies().as_dict().get('cf_clearance'):
        logger.error(f"retry {i+1} times, browser_cookie is {browser.cookies().as_dict()}")
        continue
    else:
        logger.success(f"retry {i+1} times, browser_cookie is {browser.cookies().as_dict()}")
        break
# with open(r"./ccc.html", "w") as f:
#     f.write(browser.html)
browser.wait(2)
browser.wait.ele_displayed('x://td[@class="subject"]/a', timeout=3)
for tr in browser.eles('x://div[@class="boardList mgt60"]//tr', timeout=3)[1:]:
    tds = [td.text for td in tr.eles("x://td", timeout=3)]
    detail_url = tr.ele('x://td[@class="subject"]/a').attr('href')
    logger.info(f"list_page_company is {tds} , a_href is {detail_url}")
# 对整页截图并保存
# browser.get_screenshot(path=r'./headless_False.png', full_page=True)
browser.get_screenshot(path=r'./headless_True.png', full_page=True)
browser.quit()
```